\section{Algorithmic Flow / Pseudocode/Mathematical Model}

The core functionality of the proposed system relies on two distinct mathematical frameworks: Normalizing Flows for the acoustic model and Generative Adversarial Networks (GANs) for the vocoder. This section defines the mathematical objectives and the algorithmic flow for both training and inference.

\subsection{Acoustic Modeling: Flowtron}

Flowtron functions as a generative model by maximizing the log-likelihood of the training data. It learns an invertible mapping $f: \mathcal{Z} \rightarrow \mathcal{X}$, transforming a simple latent distribution $p(\mathbf{z})$ (typically a spherical Gaussian) into the complex distribution of mel-spectrograms $p(\mathbf{x})$.

\subsubsection{Log-Likelihood Maximization}
The training objective is derived using the change of variables formula. For a sequence of observed mel-spectrogram frames $\mathbf{x}$, the log-likelihood is maximized as follows:

\begin{equation}
    \log p_\theta(\mathbf{x}) = \log p_\theta(\mathbf{z}) + \sum_{i=1}^{k} \log \left| \det \left( \frac{\partial f^{-1}_i(\mathbf{x})}{\partial \mathbf{x}} \right) \right|
\end{equation}

Where:
\begin{itemize}
    \item $\mathbf{z}$ is the latent variable obtained by passing $\mathbf{x}$ through the inverse flow steps: $\mathbf{z} = f^{-1}_k \circ f^{-1}_{k-1} \circ \dots \circ f^{-1}_0(\mathbf{x})$.
    \item $p_\theta(\mathbf{z})$ is the prior distribution $\mathcal{N}(\mathbf{z}; 0, \mathbf{I})$.
    \item The second term represents the sum of the log-determinants of the Jacobian matrices of the inverse transformations, which ensures the volume of the probability density is conserved.
\end{itemize}

\subsubsection{Affine Coupling Layer}
To ensure the Jacobian determinant is computationally tractable (triangular), Flowtron utilizes Affine Coupling Layers. For a given step of flow, the input $\mathbf{x}$ is split, and the transformation is applied as:

\begin{equation}
    (\log \mathbf{s}_t, \mathbf{b}_t) = \text{NN}(\mathbf{x}_{1:t-1}, \text{text\_embedding}, \text{speaker\_id})
\end{equation}

\begin{equation}
    \mathbf{x}'_t = \mathbf{s}_t \odot \mathbf{x}_t + \mathbf{b}_t
\end{equation}

Here, $\mathbf{s}_t$ (scale) and $\mathbf{b}_t$ (bias) are generated by a neural network (NN) conditioned on the input text and previous time steps. This structure allows the model to be autoregressive and invertible.

\subsection{Waveform Synthesis: HiFi-GAN}

The vocoder acts as a generator $G$ trained against two discriminators: the Multi-Period Discriminator (MPD) and the Multi-Scale Discriminator (MSD). The training objective is a composite loss function designed to balance adversarial deception and spectral accuracy.

\subsubsection{Adversarial Loss}
We employ the least squares GAN objective for stable training. The discriminator $D$ tries to classify ground truth audio as 1 and synthesized audio as 0, while the generator tries to fool $D$:

\begin{equation}
    \mathcal{L}_{Adv}(D; G) = \mathbb{E}_{(x, s)} \left[ (D(x) - 1)^2 + (D(G(s)))^2 \right]
\end{equation}

\begin{equation}
    \mathcal{L}_{Adv}(G; D) = \mathbb{E}_{s} \left[ (D(G(s)) - 1)^2 \right]
\end{equation}

Where $x$ is the ground truth audio and $s$ is the input mel-spectrogram condition.

\subsubsection{Feature Matching and Mel-Spectrogram Loss}
To prevent artifacts common in GAN synthesis, two auxiliary losses are added. The Feature Matching loss minimizes the $L1$ distance between intermediate feature maps of the discriminator:

\begin{equation}
    \mathcal{L}_{FM}(G; D) = \mathbb{E}_{(x, s)} \left[ \sum_{i=1}^{T} \frac{1}{N_i} || D^i(x) - D^i(G(s)) ||_1 \right]
\end{equation}

Additionally, the Mel-Spectrogram loss ensures the spectral consistency of the generated waveform:

\begin{equation}
    \mathcal{L}_{Mel}(G) = \mathbb{E}_{(x, s)} \left[ || \phi(x) - \phi(G(s)) ||_1 \right]
\end{equation}

The final objective for the generator combines these components with hyperparameters $\lambda_{fm} = 2$ and $\lambda_{mel} = 45$:

\begin{equation}
    \mathcal{L}_{G} = \mathcal{L}_{Adv}(G; D) + \lambda_{fm}\mathcal{L}_{FM}(G; D) + \lambda_{mel}\mathcal{L}_{Mel}(G)
\end{equation}

\begin{figure}[h]
    \centering
    \fbox{\begin{minipage}{0.9\textwidth}
        \centering
        \vspace{1cm}
        \textbf{PLACEHOLDER: Training Loop Flowchart} \\
        \vspace{0.5cm}
        \textit{Guidance: Insert a flowchart illustrating the parallel training processes. The left side should show Flowtron minimizing NLL (Negative Log-Likelihood) using Mel-spectrograms and Text. The right side should show HiFi-GAN Generator producing Audio, passed to MPD/MSD Discriminators, calculating L\_Adv, L\_FM, and L\_Mel losses.}
        \vspace{1cm}
    \end{minipage}}
    \caption{Mathematical optimization flow for the proposed Bangla TTS pipeline.}
    \label{fig:math_flow}
\end{figure}

\subsection{Inference Algorithmic Flow}

The complete process for synthesizing Bangla speech from text during the inference phase is detailed in Algorithm \ref{alg:inference}.

\begin{algorithm}[H]
\caption{End-to-End Bangla Speech Synthesis}
\label{alg:inference}
\begin{algorithmic}[1]
\REQUIRE Raw Bangla Text $T_{raw}$, Speaker ID $S_{id}$
\ENSURE Audio Waveform $W$

\STATE \textbf{Stage 1: Text Preprocessing}
\STATE $T_{norm} \leftarrow \text{BanglaNormalizer}(T_{raw})$ \COMMENT{Normalize dates, numbers, etc.}
\STATE $P_{seq} \leftarrow \text{G2P}(T_{norm})$ \COMMENT{Convert to IPA phonemes}
\STATE $E_{text} \leftarrow \text{Encoder}(P_{seq})$ \COMMENT{Get embedding sequence}

\STATE \textbf{Stage 2: Acoustic Modeling (Flowtron)}
\STATE Sample latent variable $\mathbf{z} \sim \mathcal{N}(0, \sigma^2 \mathbf{I})$ \COMMENT{Sample from prior}
\FOR{$t = 1$ to $Steps$}
    \STATE $(\mathbf{s}, \mathbf{b}) \leftarrow \text{NN}(\mathbf{z}, E_{text}, S_{id})$
    \STATE $\mathbf{z} \leftarrow \frac{\mathbf{z} - \mathbf{b}}{\mathbf{s}}$ \COMMENT{Apply inverse flow transformation}
\ENDFOR
\STATE $M_{spec} \leftarrow \mathbf{z}$ \COMMENT{Result is the Mel-spectrogram}

\STATE \textbf{Stage 3: Vocoding (HiFi-GAN)}
\STATE $W \leftarrow \text{Generator}(M_{spec})$ \COMMENT{Upsample Mel to Waveform}
\RETURN $W$
\end{algorithmic}
\end{algorithm}
